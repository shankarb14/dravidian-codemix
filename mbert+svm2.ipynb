{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mbert+svm2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkHS68fkzNft"
      },
      "source": [
        "import subprocess\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import pickle\n",
        "\n",
        "df = pd.read_csv('/content/hate_speech.tsv', sep='\\t').fillna(' ') #read_excel('/content/train.xlsx')\n",
        "print(df.head())\n",
        "# Create a list of punctuation marks\n",
        "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
        " '•', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
        " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
        " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
        " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√']\n",
        "\n",
        "# Code to replace punctuations with whitespaces\n",
        "def clean_text(x):\n",
        "    x = str(x)\n",
        "    for punct in puncts:\n",
        "        if punct in x:\n",
        "            x = x.replace(punct, ' ')\n",
        "    return x\n",
        "df['Cleaned'] = df['Text'].apply(lambda x: re.sub(r'http\\S+', '', x))\n",
        "df['Cleaned'] = df['Cleaned'].apply(lambda x: re.sub(\"@[\\w]*\", '', x))\n",
        "df['Cleaned'] = df['Cleaned'].apply(lambda x: clean_text(x))\n",
        "df['Cleaned'] = df['Cleaned'].str.lower()\n",
        "df['Cleaned'] = df['Cleaned'].apply(lambda x:' '.join(x.split()))\n",
        "df['Sentiment'] = df['Label']\n",
        "df = df.drop(['Text','Label'],axis=1)\n",
        "print(df.head())\n",
        "batch=df[0:4000]\n",
        "!pip install transformers\n",
        "import torch\n",
        "from torch.autograd import Variable\n",
        "from torch import IntTensor\n",
        "import transformers as ppb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "from transformers import BertTokenizer, TFBertModel\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
        "model = TFBertModel.from_pretrained(\"bert-base-multilingual-cased\")\n",
        "\n",
        "tokenized = batch['Cleaned'].apply((lambda x: tokenizer.encode(x, add_special_tokens=True,max_length=40,truncation=True)))\n",
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "  #print(len(i))\n",
        "  if len(i) > max_len:\n",
        "    max_len = len(i)\n",
        "\n",
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])\n",
        "\n",
        "print(padded)\n",
        "output = model(padded)\n",
        "embedding=output.last_hidden_state\n",
        "features = embedding[:,0,:].numpy()\n",
        "y =batch['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGeMRv-uzY85"
      },
      "source": [
        "from sklearn import svm\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "train_features, test_features, train_labels, test_labels = train_test_split(features, y,  test_size=0.3,random_state=50)\n",
        "#Import svm model\n",
        "from sklearn import svm\n",
        "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
        "svc = svm.SVC()\n",
        "clf = GridSearchCV(svc, parameters,cv=10)\n",
        "clf.fit(train_features,train_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkV70HIK2DlX"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}